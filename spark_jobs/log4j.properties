# Spark Log4j 설정
# Kafka Consumer 관련 INFO 로그를 WARN으로 필터링

# Root logger
log4j.rootCategory=WARN, console

# Console appender
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Spark 관련 로그 (필요한 것만 INFO)
log4j.logger.org.apache.spark=WARN
log4j.logger.org.apache.spark.sql=WARN
log4j.logger.org.apache.spark.sql.streaming=INFO

# Kafka Consumer 관련 로그를 WARN으로 (NotCoordinatorException 등 INFO 로그 제거)
log4j.logger.org.apache.kafka.clients.consumer=WARN
log4j.logger.org.apache.kafka.clients.consumer.internals=WARN
log4j.logger.org.apache.kafka.clients.consumer.internals.AbstractCoordinator=WARN

# Kafka 일반 로그
log4j.logger.org.apache.kafka=WARN

# Zookeeper 관련 로그
log4j.logger.org.apache.zookeeper=WARN

# 중요한 Spark Streaming 로그는 유지
log4j.logger.org.apache.spark.sql.execution.streaming.MicroBatchExecution=INFO

