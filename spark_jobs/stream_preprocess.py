"""
Kafka ìŠ¤íŠ¸ë¦¼ ì „ì²˜ë¦¬: aggTrade â†’ 1ë¶„ë´‰(OHLCV) ì§‘ê³„ í›„ ì½˜ì†” ì¶œë ¥.

- binance-trade(aggTrade)ë¥¼ ì½ì–´ì„œ 1ë¶„ tumbling windowë¡œ ì§‘ê³„
- open=first(price), high=max, low=min, close=last, volume=sum(qty), count=ì²´ê²°ê±´ìˆ˜
- ì´í›„ ClickHouse ì ì¬ëŠ” foreachBatchë¡œ í™•ì¥ ê°€ëŠ¥

ì‹¤í–‰: ìŠ¤íŒŒí¬ ë§ˆìŠ¤í„° ì»¨í…Œì´ë„ˆì—ì„œ
  spark-submit --master spark://spark-master:7077 --packages ... stream_preprocess.py
ë˜ëŠ” ./scripts/start-spark-job.sh ì—ì„œ ì´ íŒŒì¼ë¡œ ë³€ê²½
"""
import time
from pyspark.sql import SparkSession
# ë°ì´í„° ì²˜ë¦¬ì— í•„ìš”í•œ ë„êµ¬ë“¤ (íŠ¹íˆ windowëŠ” ì‹œê°„ ìª¼ê°œëŠ” ë„êµ¬)
from pyspark.sql.functions import (
    col, first, last, min as spark_min, max as spark_max, sum as spark_sum, count,
    window, from_unixtime,
)
# kafka_readerì—ì„œ ë§Œë“  ë°ì´í„° ë¶ˆëŸ¬ì˜´
from kafka_reader import create_spark_session, read_from_kafka, parse_trade_data


def agg_trade_to_1m_ohlcv(parsed_trade_df):
    """
    aggTrade íŒŒì‹± ê²°ê³¼ë¥¼ 1ë¶„ tumbling windowë¡œ ì§‘ê³„ â†’ OHLCV.
    event_time_sec ê¸°ì¤€ìœ¼ë¡œ 1ë¶„ êµ¬ê°„ ë¬¶ìŒ.
    with_tsë‚´ì—ì„œ col("event_time_sec")ëŠ” ë°”ì´ë‚¸ã……ì—ì„œ ì²˜ìŒ ì˜¨ ë°ì´í„°
    from_unixtime(): ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ë¬¸ìì—´ë¡œ ë°”ê¿ˆ + sparkê°€ ê³„ì‚°í•˜ê¸° ìœ„í•´ timestapë¡œ ë³€ê²½. 
    ë˜í•œ unixtimeì´ ì´ˆë‹¨ìœ„ë¼ê³  í™•ì‹¤í•˜ê²Œ ì•Œë ¤ì¤Œ(ë°€ë¦¬ì´ˆë‹¨ìœ„ / ì´ˆë‹¨ìœ„ ì˜ êµ¬ë¶„í•´ì¤Œ)
    "event_ts"ëŠ” ë³€í™˜ëœ ì‹œê°„ ê°ì²´ê°€ ë‹´ê¸¸ ìƒˆë¡œìš´ ì»¬ëŸ¼ ì´ë¦„
    with_ts: event_ts ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ìƒˆë¡œìš´ ë°ì´í„° í”„ë ˆì„
    with_window ë‚´ë¶€: Tumbling Window ê¸°ë²•.event_tsë¥¼ ê¸°ì¤€ìœ¼ë¡œ 0~59ì´ˆê¹Œì§€ë¥¼ í•˜ë‚˜ì˜ ìƒìë¡œ ë¬¶ìŒ
    agg(...): ë­‰ì³ì§„ ë°ì´í„°ë“¤ì„ ëŒ€ìƒìœ¼ë¡œ ìˆ˜í•™ì  ê³„ì‚° ì§„í–‰
    selectL ê³„ì‚°ì€ ëë‚¬ì§€ë§Œ window ì»¬ëŸ¼ì´ êµ¬ì¡°ì²´ í˜•íƒœ({start, end}) í˜•íƒœë¼ì„œ ì§ë ¬í™” í•¨.
    """
    # ì´ˆ ë‹¨ìœ„ â†’ timestamp (ìœˆë„ìš° í•¨ìˆ˜ìš©)
    with_ts = parsed_trade_df.withColumn(
        "event_ts",
        from_unixtime(col("event_time_sec")).cast("timestamp")
    )
    with_window = with_ts.withColumn("window", window(col("event_ts"), "1 minute"))

    return with_window.groupBy("window", "symbol").agg(
        first("price").alias("open"),
        spark_max("price").alias("high"),
        spark_min("price").alias("low"),
        last("price").alias("close"),
        spark_sum("quantity").alias("volume"),
        count("*").alias("trades_count"),
    ).select(
        col("window.start").alias("window_start"),
        col("symbol"),
        col("open"), col("high"), col("low"), col("close"),
        col("volume"), col("trades_count"),
    )


def main():
    spark = create_spark_session("StreamPreprocess-1mOHLCV")

    # KafkaëŠ” ì´ë¯¸ start.shë¡œ ì‹¤í–‰ ì¤‘. Consumer ì—°ê²° ì „ ì§§ì€ ëŒ€ê¸°ë§Œ (ì¬ì‹œì‘ ì§í›„ coordinator ëŒ€ë¹„)
    print("â³ Kafka ì—°ê²° ì „ ëŒ€ê¸° (5ì´ˆ)...")
    time.sleep(5)

    print("ğŸ“¥ binance-trade êµ¬ë… ì¤‘...")
    kafka_df = read_from_kafka(spark, "binance-trade", starting_offsets="latest")

    parsed = parse_trade_data(kafka_df)
    ohlcv_1m = agg_trade_to_1m_ohlcv(parsed)

    print("ğŸš€ 1ë¶„ë´‰ ì§‘ê³„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ (1ë¶„ë§ˆë‹¤ íŠ¸ë¦¬ê±°)...")
    """
    writeStream: ì§€ê¸ˆê¹Œì§€ ì‘ì„±í•œ ì½”ë“œ(readStreanm agg)ëŠ” ì‹¤ì œë¡œëŠ” ì•„ë¬´ ì¼ë„ í•˜ì§€ ì•Šê³  ê²Œíšë§Œ ì„¸ìš´ ìƒíƒœ
    writestreamì„ ë§Œë‚˜ëŠ” ìˆœê°€ sparkëŠ” ì‹œì‘í•¨.
    .outputMode: ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì¶œë ¥ ì—¬ëŸ¬ ë°©ì‹ ìˆì§€ë§Œ, 1ë¶„ë´‰ì—ëŠ” update ëª¨ë“œ íš¨ìœ¨ì 
    update ëª¯: 1ë¶„ì´ ì§€ë‚  ë•Œë§ˆë‹¤ ìƒˆë¡­ê²Œ ê³„ì‹¼ëœ 1ë¶„ë´‰ ê²°ê³¼ê°’ë§Œ ë”± ì°ì–´ì¤Œ (ë°”ë€ ë°ì´í„°ë§Œ ë³´ì—¬ì¤Œ)
    format(console) ê²°ê³¼ë¬¼ DBì— ì €ì¥í•˜ì§€ ì•Šê³  ì¼ë‹¨ í„°ë¯¸ë„ ì½˜ì†” ì¶œë ¥
    option("truncate", False): ë°ì´í„° ê¸¸ë©´ ...ìœ¼ë¡œ ìƒëµí•˜ëŠ”ë°, ìƒëµí•˜ì§€ë§ê³  ì „ì²´ ë‹¤
    .option(checkpoint...): ì„¸ì´ë¸Œ í¬ì¸íŠ¸(í”„ë¡œê·¸ë¨ êº¼ì§ˆ ë•Œ, ë°ì´í„° ë§ˆì§€ë§‰ ë¶€ë¶„ ì €ì¥)
    .trigger: 1ë¶„ ì£¼ê¸°
    .start() ì‹œì‘
    """
    query = ohlcv_1m.writeStream \
        .outputMode("update") \
        .format("console") \
        .option("truncate", False) \
        .option("checkpointLocation", "/tmp/checkpoint-preprocess-1m") \
        .trigger(processingTime="1 minute") \
        .start()

    query.awaitTermination() # ëë‚ ë•Œê¹Œì§€ ëŒ€ê¸° (ì‚¬ìš©ìê°€ ì¢…ë£Œ ì „ê¹Œì§€ ì§„í–‰)ê¸€ê¸€


if __name__ == "__main__":
    main()
