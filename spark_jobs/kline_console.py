"""
Binance kline_1m í† í”½ êµ¬ë… â†’ íŒŒì‹± í›„ ì½˜ì†” ì¶œë ¥.
ìš°ë¦¬ê°€ aggTradeë¡œ ë§Œë“  1ë¶„ë´‰(stream_preprocess)ê³¼ ë¹„êµìš©.

ì‹¤í–‰: ./scripts/start-spark-job.sh kline
"""
import time
from pyspark.sql.functions import from_unixtime, col
from kafka_reader import create_spark_session, read_from_kafka, parse_kline_data


def main():
    spark = create_spark_session("BinanceKlineConsole")

    print("â³ Kafka ì—°ê²° ì „ ëŒ€ê¸° (5ì´ˆ)...")
    time.sleep(5)

    print("ğŸ“¥ binance-kline(Binance 1ë¶„ë´‰) êµ¬ë… ì¤‘...")
    kafka_df = read_from_kafka(spark, "binance-kline", starting_offsets="latest")

    parsed = parse_kline_data(kafka_df)
    # window_start_sec â†’ timestamp ì»¬ëŸ¼ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ
    with_ts = parsed.withColumn(
        "window_start",
        from_unixtime(col("window_start_sec")).cast("timestamp")
    ).select(
        "window_start", "symbol", "open", "high", "low", "close", "volume", "trades", "is_candle_closed"
    )

    print("ğŸš€ Binance 1ë¶„ë´‰ ìŠ¤íŠ¸ë¦¬ë° (1ë¶„ë§ˆë‹¤ íŠ¸ë¦¬ê±°)...")
    query = with_ts.writeStream \
        .outputMode("append") \
        .format("console") \
        .option("truncate", False) \
        .option("checkpointLocation", "/tmp/checkpoint-kline-console") \
        .trigger(processingTime="1 minute") \
        .start()

    query.awaitTermination()


if __name__ == "__main__":
    main()
